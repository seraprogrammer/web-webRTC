<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>WebRTC Video Call</title>
  <script src="https://cdn.socket.io/4.0.1/socket.io.min.js"></script>
  <style>
    body {
      font-family: Arial, sans-serif;
      max-width: 1000px;
      margin: 0 auto;
      padding: 20px;
    }

    .video-container {
      display: flex;
      gap: 20px;
      margin: 20px 0;
      flex-wrap: wrap;
    }

    .video-wrapper {
      flex: 1;
      min-width: 300px;
    }

    video {
      width: 100%;
      height: 300px;
      border: 1px solid #ccc;
      background: #f0f0f0;
      border-radius: 8px;
    }

    .controls {
      margin: 20px 0;
      display: flex;
      gap: 10px;
      flex-wrap: wrap;
    }

    .status {
      color: #666;
      margin: 10px 0;
      padding: 10px;
      background-color: #f8f8f8;
      border-radius: 4px;
      max-height: 200px;
      overflow-y: auto;
    }

    button {
      padding: 8px 16px;
      background-color: #4285f4;
      color: white;
      border: none;
      border-radius: 4px;
      cursor: pointer;
      font-size: 14px;
    }

    button:hover {
      background-color: #357ae8;
    }

    button:disabled {
      background-color: #cccccc;
      cursor: not-allowed;
    }

    h2 {
      color: #333;
    }

    .audio-controls {
      display: flex;
      align-items: center;
      gap: 10px;
      margin-top: 10px;
    }

    .volume-slider {
      width: 150px;
    }
  </style>
</head>

<body>
  <h2>WebRTC Real-time Video Call</h2>

  <div class="status" id="connectionStatus">Status: Not connected</div>

  <div class="video-container">
    <div class="video-wrapper">
      <h3>Local Video</h3>
      <video id="localVideo" autoplay playsinline muted></video>
      <div class="audio-controls">
        <input type="checkbox" id="muteLocalAudio">
        <label for="muteLocalAudio">Mute Microphone</label>
      </div>
    </div>
    <div class="video-wrapper">
      <h3>Remote Video</h3>
      <video id="remoteVideo_1" autoplay playsinline></video>
      <div class="audio-controls">
        <label for="remoteVolume_1">Volume:</label>
        <input type="range" id="remoteVolume_1" class="volume-slider" min="0" max="1" step="0.1" value="1">
        <span id="volumeLevel_1">100%</span>
      </div>
    </div>
  </div>

  <div class="controls">
    <button id="startCall">Start Call</button>
    <button id="endCall" disabled>End Call</button>
    <button id="checkAudio" disabled>Check Audio</button>
    <button id="reconnect" disabled>Reconnect</button>
  </div>

  <script>
    // Connection details
    const serverUrl = "https://webrtc-production-6f32.up.railway.app";
    const roomId = "1234"; // Use a unique room ID
    const socket = io(serverUrl);

    // WebRTC variables
    let localStream;
    let peerConnections = {};
    let isInitiator = false;
    let audioContext;
    let audioAnalyser;

    // Better ICE server configuration with multiple STUN and TURN servers
    const config = {
      iceServers: [
        { urls: "stun:stun.l.google.com:19302" },
        { urls: "stun:stun1.l.google.com:19302" },
        { urls: "stun:stun2.l.google.com:19302" },
        { urls: "stun:stun3.l.google.com:19302" },
        { urls: "stun:stun4.l.google.com:19302" },
        {
          urls: 'turn:numb.viagenie.ca',
          username: 'webrtc@live.com',
          credential: 'muazkh'
        },
        {
          urls: 'turn:turn.anyfirewall.com:443?transport=tcp',
          username: 'webrtc',
          credential: 'webrtc'
        }
      ],
      // Optional: Improve WebRTC connections by using modern options
      iceTransportPolicy: 'all',
      bundlePolicy: 'max-bundle',
      rtcpMuxPolicy: 'require',
      sdpSemantics: 'unified-plan'
    };

    // DOM elements
    const localVideo = document.getElementById('localVideo');
    const remoteVideo = document.getElementById('remoteVideo_1');
    const startCallButton = document.getElementById('startCall');
    const endCallButton = document.getElementById('endCall');
    const checkAudioButton = document.getElementById('checkAudio');
    const reconnectButton = document.getElementById('reconnect');
    const connectionStatus = document.getElementById('connectionStatus');
    const muteLocalAudioCheckbox = document.getElementById('muteLocalAudio');
    const remoteVolumeSlider = document.getElementById('remoteVolume_1');
    const volumeLevel = document.getElementById('volumeLevel_1');

    // Start call button handler
    startCallButton.addEventListener('click', startCall);
    endCallButton.addEventListener('click', endCall);
    checkAudioButton.addEventListener('click', checkAudioTracks);
    reconnectButton.addEventListener('click', reconnect);

    // Mute local audio handler
    muteLocalAudioCheckbox.addEventListener('change', (e) => {
      if (localStream) {
        localStream.getAudioTracks().forEach(track => {
          track.enabled = !e.target.checked;
        });
        updateStatus(`Local microphone ${e.target.checked ? 'muted' : 'unmuted'}`);
      }
    });

    // Remote volume control
    remoteVolumeSlider.addEventListener('input', (e) => {
      const volume = e.target.value;
      remoteVideo.volume = volume;
      volumeLevel.textContent = `${Math.round(volume * 100)}%`;
    });

    // Multiple status messages with timestamp
    let statusLog = [];
    function updateStatus(message) {
      const now = new Date();
      const timestamp = `${now.getHours()}:${now.getMinutes()}:${now.getSeconds()}`;
      const logEntry = `[${timestamp}] ${message}`;

      statusLog.push(logEntry);
      if (statusLog.length > 20) statusLog.shift(); // Keep last 20 messages

      connectionStatus.textContent = statusLog.join('\n');
      console.log(message);
    }

    // Initialize and join room
    async function startCall() {
      try {
        updateStatus("Requesting camera and microphone access...");
        localStream = await navigator.mediaDevices.getUserMedia({
          video: true,
          audio: {
            echoCancellation: true,
            noiseSuppression: true,
            autoGainControl: true,
            sampleRate: 48000 // Ensure high quality audio
          }
        });

        localVideo.srcObject = localStream;
        updateStatus("Camera and microphone accessed. Joining room...");

        // Check local audio tracks are available
        const audioTracks = localStream.getAudioTracks();
        updateStatus(`Local audio tracks: ${audioTracks.length}. Enabled: ${audioTracks.length > 0 ? audioTracks[0].enabled : 'N/A'
          }`);

        // Initialize WebRTC
        createPeerConnection();

        // Join the room
        socket.emit("join-room", roomId);
        startCallButton.disabled = true;
        endCallButton.disabled = false;
        checkAudioButton.disabled = false;
        reconnectButton.disabled = false;

        // Setup audio analyzer
        setupAudioAnalyzer();

        // Start monitoring stats
        startStatsMonitoring();
      } catch (error) {
        updateStatus(`Error: ${error.name} - ${error.message}`);
        console.error("Error starting call:", error);

        if (error.name === 'NotFoundError' || error.name === 'DevicesNotFoundError') {
          alert("Camera or microphone not found. Please check your devices and permissions.");
        } else if (error.name === 'NotAllowedError' || error.name === 'PermissionDeniedError') {
          alert("Camera or microphone permission denied. Please allow access to your devices.");
        } else {
          alert(`Error starting call: ${error.message}`);
        }
      }
    }

    // Create WebRTC peer connection
    function createPeerConnection() {
      try {
        const pc = new RTCPeerConnection(config);
        peerConnections[1] = pc; // Store the connection

        // Add local media tracks to the connection
        if (localStream) {
          localStream.getTracks().forEach(track => {
            pc.addTrack(track, localStream);
            updateStatus(`Added local ${track.kind} track to peer connection for user 1`);
          });
        }

        // Handle ICE candidates
        pc.onicecandidate = event => {
          if (event.candidate) {
            socket.emit("ice-candidate", {
              candidate: event.candidate,
              roomId,
              1 // Include userId for the specific connection
            });
            updateStatus(`Sent ICE candidate to user 1`);
          }
        };

        // Log ICE gathering state changes
        pc.onicegatheringstatechange = () => {
          updateStatus(`ICE gathering state: ${pc.iceGatheringState}`);
        };

        // Log ICE connection state changes
        pc.oniceconnectionstatechange = () => {
          updateStatus(`ICE Connection State: ${pc.iceConnectionState}`);

          if (pc.iceConnectionState === 'failed') {
            updateStatus("Connection failed. Attempting to restart ICE...");
            pc.restartIce();
          } else if (pc.iceConnectionState === 'disconnected') {
            updateStatus("Connection disconnected. You may need to reconnect.");
          } else if (pc.iceConnectionState === 'connected') {
            updateStatus("Connection established successfully!");
          }
        };

        // Log connection state changes
        pc.onconnectionstatechange = () => {
          updateStatus(`Connection state: ${pc.connectionState}`);
        };

        // Log signaling state changes
        pc.onsignalingstatechange = () => {
          updateStatus(`Signaling state: ${pc.signalingState}`);
        };

        // Handle remote media streams
        pc.ontrack = event => {
          if (event.streams && event.streams[0]) {
            remoteVideo.srcObject = event.streams[0];
            updateStatus(`Received track from user 1`);

            // Set audio output to default speaker if supported
            if (typeof remoteVideo.setSinkId === 'function') {
              remoteVideo.setSinkId('default')
                .then(() => updateStatus("Audio output set to default speaker"))
                .catch(error => updateStatus(`Error setting audio output: ${error.message}`));
            }

            // Check audio tracks after a delay
            setTimeout(checkAudioTracks, 1000);

            // Monitor remote audio tracks
            if (event.track.kind === 'audio') {
              monitorRemoteAudioTrack(event.track);
            }
          }
        };

        updateStatus("WebRTC peer connection created");

        // Create offer and send to the new user
        const offerOptions = {
          offerToReceiveAudio: true,
          offerToReceiveVideo: true,
          voiceActivityDetection: true
        };
        pc.createOffer(offerOptions).then(offer => {
          return pc.setLocalDescription(offer);
        }).then(() => {
          socket.emit("offer", { offer: pc.localDescription, roomId, 1 });
        }).catch(error => {
          console.error("Error creating offer:", error);
          updateStatus(`Error creating offer for user 1: ${error.message}`);
        });

      } catch (error) {
        console.error("Error creating peer connection:", error);
        updateStatus(`Error creating peer connection for user 1: ${error.message}`);
      }
    }

    // Function to check and enable audio tracks
    function checkAudioTracks() {
      updateStatus("Checking audio tracks...");

      // Check local audio
      if (localStream) {
        const localAudioTracks = localStream.getAudioTracks();
        updateStatus(`Local audio tracks: ${localAudioTracks.length}. Enabled: ${localAudioTracks.length > 0 ? localAudioTracks[0].enabled : 'N/A'
          }`);
      }

      // Check remote audio
      if (remoteVideo.srcObject) {
        const remoteAudioTracks = remoteVideo.srcObject.getAudioTracks();

        updateStatus(`Remote audio tracks: ${remoteAudioTracks.length}. Enabled: ${remoteAudioTracks.length > 0 ? remoteAudioTracks[0].enabled : 'N/A'
          }`);

        // Make sure remote audio tracks are enabled
        if (remoteAudioTracks.length > 0) {
          remoteAudioTracks.forEach(track => {
            track.enabled = true;
            updateStatus(`Ensuring remote audio track is enabled`);
          });
        } else {
          updateStatus("⚠️ Warning: No remote audio tracks found!");
        }

        // Ensure volume is up
        remoteVideo.volume = 1.0;
        remoteVolumeSlider.value = 1.0;
        volumeLevel.textContent = "100%";
      } else {
        updateStatus("⚠️ No remote stream available yet");
      }

      // Get connection stats
      displayAudioStats();
    }

    // Function to reconnect the call
    function reconnect() {
      updateStatus("Attempting to reconnect...");

      // Close existing connection
      if (peerConnections[1]) {
        peerConnections[1].close();
        peerConnections[1] = null;
      }

      // Create new connection
      createPeerConnection();

      // Re-join the room
      socket.emit("join-room", roomId);
    }

    // Setup audio analyzer to monitor audio levels
    function setupAudioAnalyzer() {
      try {
        if (!audioContext) {
          audioContext = new (window.AudioContext || window.webkitAudioContext)();
        }

        if (localStream) {
          const audioSource = audioContext.createMediaStreamSource(localStream);
          audioAnalyser = audioContext.createAnalyser();
          audioAnalyser.fftSize = 256;
          audioSource.connect(audioAnalyser);

          // Monitor local audio levels
          monitorLocalAudioLevels();
        }
      } catch (error) {
        updateStatus(`Audio analyzer error: ${error.message}`);
      }
    }

    // Monitor local audio levels
    function monitorLocalAudioLevels() {
      if (!audioAnalyser) return;

      const dataArray = new Uint8Array(audioAnalyser.frequencyBinCount);

      function checkAudioLevel() {
        if (!audioAnalyser) return;

        audioAnalyser.getByteFrequencyData(dataArray);
        let sum = 0;
        for (let i = 0; i < dataArray.length; i++) {
          sum += dataArray[i];
        }
        const average = sum / dataArray.length;

        // Log only significant audio activity to avoid spamming
        if (average > 30) {
          updateStatus(`Local audio level: ${Math.round(average)}/255`);
        }

        // Continue monitoring if call is active
        if (peerConnections[1]) {
          requestAnimationFrame(checkAudioLevel);
        }
      }

      checkAudioLevel();
    }

    // Monitor remote audio track
    function monitorRemoteAudioTrack(audioTrack) {
      updateStatus(`Monitoring remote audio track: ${audioTrack.id}`);

      audioTrack.onmute = () => updateStatus("⚠️ Remote audio track muted");
      audioTrack.onunmute = () => updateStatus("Remote audio track unmuted");
      audioTrack.onended = () => updateStatus("⚠️ Remote audio track ended");
    }

    // Display audio statistics
    function displayAudioStats() {
      if (!peerConnections[1]) return;

      peerConnections[1].getStats(null).then(stats => {
        let hasAudioStats = false;

        stats.forEach(report => {
          if (report.type === 'inbound-rtp' && report.kind === 'audio') {
            hasAudioStats = true;
            updateStatus(`Audio stats: packets received=${report.packetsReceived}, packets lost=${report.packetsLost || 0}, jitter=${report.jitter || 0}`);
          }

          if (report.type === 'outbound-rtp' && report.kind === 'audio') {
            updateStatus(`Audio outbound: packets sent=${report.packetsSent}`);
          }
        });

        if (!hasAudioStats) {
          updateStatus("No audio statistics available yet");
        }
      }).catch(error => {
        updateStatus(`Error getting stats: ${error.message}`);
      });
    }

    // Start monitoring WebRTC stats
    function startStatsMonitoring() {
      const statsInterval = setInterval(() => {
        if (peerConnections[1] && peerConnections[1].connectionState === 'connected') {
          displayAudioStats();
        } else if (!peerConnections[1]) {
          clearInterval(statsInterval);
        }
      }, 10000); // Check every 10 seconds
    }

    // End the call
    function endCall() {
      if (peerConnections[1]) {
        peerConnections[1].close();
        peerConnections[1] = null;
      }

      if (localStream) {
        localStream.getTracks().forEach(track => track.stop());
        localStream = null;
      }

      if (audioContext) {
        audioContext.close();
        audioContext = null;
        audioAnalyser = null;
      }

      localVideo.srcObject = null;
      remoteVideo.srcObject = null;

      startCallButton.disabled = false;
      endCallButton.disabled = true;
      checkAudioButton.disabled = true;
      reconnectButton.disabled = true;

      updateStatus("Call ended");
    }

    // Socket.io event handlers
    socket.on("connect", () => {
      updateStatus("Connected to signaling server");
    });

    socket.on("connect_error", (error) => {
      updateStatus(`Signaling server connection error: ${error.message}`);
    });

    socket.on("user-connected", async (userId) => {
      updateStatus(`User connected: ${userId}. Creating offer...`);
      createPeerConnection(userId); // Create a peer connection for the new user
    });

    socket.on("offer", async ({ offer, userId }) => {
      try {
        updateStatus(`Received offer from user ${userId}. Creating answer...`);
        createPeerConnection(userId); // Create a peer connection for the user

        const pc = peerConnections[userId];
        await pc.setRemoteDescription(new RTCSessionDescription(offer));
        const answer = await pc.createAnswer();
        await pc.setLocalDescription(answer);
        socket.emit("answer", { answer, roomId, userId });
      } catch (error) {
        console.error("Error handling offer:", error);
        updateStatus(`Error handling offer from user ${userId}: ${error.message}`);
      }
    });

    socket.on("answer", async ({ answer, userId }) => {
      try {
        updateStatus(`Received answer from user ${userId}`);
        const pc = peerConnections[userId];
        await pc.setRemoteDescription(new RTCSessionDescription(answer));
      } catch (error) {
        console.error("Error handling answer:", error);
        updateStatus(`Error handling answer from user ${userId}: ${error.message}`);
      }
    });

    socket.on("ice-candidate", async ({ candidate, userId }) => {
      try {
        const pc = peerConnections[userId];
        if (pc) {
          await pc.addIceCandidate(new RTCIceCandidate(candidate));
          updateStatus(`Added remote ICE candidate from user ${userId}`);
        } else {
          updateStatus(`Received ICE candidate from user ${userId} but connection not ready yet`);
        }
      } catch (error) {
        console.error("Error adding ICE candidate:", error);
        updateStatus(`Error adding ICE candidate from user ${userId}: ${error.message}`);
      }
    });

    // Play event handler for remote video
    remoteVideo.onplay = () => {
      updateStatus("Remote video stream started playing");

      // Force audio output to be handled
      if (remoteVideo.srcObject && remoteVideo.srcObject.getAudioTracks().length > 0) {
        updateStatus("Remote audio tracks found in playing stream");
      }
    };

    // Connection cleanup on page unload
    window.onbeforeunload = () => {
      if (socket) {
        socket.disconnect();
      }
      endCall();
    };

    // Initial connection status
    updateStatus("Ready to start call. Click 'Start Call' to begin.");
  </script>
</body>

</html>
